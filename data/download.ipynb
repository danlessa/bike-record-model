{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4afc29-e885-43ad-b461-d53a6a0c8f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 581 Âµs (started: 2021-07-23 16:30:14 -03:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cd8e44-61d3-438b-b8f9-f280b3587066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from tqdm.auto import tqdm\n",
    "from urllib.parse import unquote\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import os\n",
    "\n",
    "FOLDER_PATH = 'raw_historical'\n",
    "URL_LIST_PATH = f'{FOLDER_PATH}/subset_M2I3NVASM_5.12.4_20210723_192925.txt'\n",
    "USERNAME = 'danlessa'\n",
    "PASSWORD = 'Pa$$w0rd'\n",
    "\n",
    "with open(URL_LIST_PATH, 'r') as fid:\n",
    "    url_list = [el.strip() \n",
    "                for el in fid.readlines()\n",
    "                if 'README' not in el]\n",
    "    \n",
    "\n",
    "def url_filename(url):\n",
    "    filename = (unquote(url).split(\"FILENAME\")[1]\n",
    "                        .split(\"&\")[0]\n",
    "                        .split(\"/\")[-1])\n",
    "    return filename\n",
    "    \n",
    "    \n",
    "files = os.listdir(FOLDER_PATH) \n",
    "url_list = [el\n",
    "            for el in url_list\n",
    "            if url_filename(el) not in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5791927a-665c-45c1-b8c9-097950a709d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: file:///Users/danlessa/Downloads/EL-HowToAccessDataWithPython-230721-1449-2632.pdf\n",
    "# overriding requests.Session.rebuild_auth to mantain headers when redirected\n",
    "class SessionWithHeaderRedirection(requests.Session):\n",
    " AUTH_HOST = 'urs.earthdata.nasa.gov'\n",
    " def __init__(self, username, password):\n",
    "     super().__init__()\n",
    "     self.auth = (username, password)\n",
    "     # Overrides from the library to keep headers when redirected to or from\n",
    "     # the NASA auth host.\n",
    " def rebuild_auth(self, prepared_request, response):\n",
    "     headers = prepared_request.headers\n",
    "     url = prepared_request.url\n",
    "     if 'Authorization' in headers:\n",
    "         original_parsed = requests.utils.urlparse(response.request.url)\n",
    "         redirect_parsed = requests.utils.urlparse(url)\n",
    "     if (original_parsed.hostname != redirect_parsed.hostname) and \\\n",
    "         redirect_parsed.hostname != self.AUTH_HOST and \\\n",
    "         original_parsed.hostname != self.AUTH_HOST:\n",
    "         del headers['Authorization']\n",
    "     return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01aa5953-b634-4bf6-b8cd-708b79fe8a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 2093\n",
      "Expected time (3s avg per file): 11.63 min\n",
      "Expected time (3s avg per file, 20x): 0.58 min\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of files: {len(url_list)}\")\n",
    "print(f\"Expected time (3s avg per file): {len(url_list) / (3 * 60) :.2f} min\")\n",
    "print(f\"Expected time (3s avg per file, 20x): {len(url_list) / (3 * 60 * 20) :.2f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ecd0a86-34c3-4a03-9cb8-f65488cdc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(session, url, output_path):\n",
    "    r = session.get(url)\n",
    "    with open(output_path, 'wb') as fid:\n",
    "        fid.write(r.content)\n",
    "        \n",
    "def download_files(url_list):\n",
    "    session = SessionWithHeaderRedirection(USERNAME, PASSWORD)\n",
    "    for url in url_list:\n",
    "        filename = (unquote(url).split(\"FILENAME\")[1]\n",
    "                                .split(\"&\")[0]\n",
    "                                .split(\"/\")[-1])\n",
    "        download_file(session, url, f\"{FOLDER_PATH}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8a5e3e-8155-46ef-8e51-9d474f35d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield n number of striped chunks from l.\"\"\"\n",
    "    for i in range(0, n):\n",
    "        yield l[i::n]\n",
    "\n",
    "N_chunks = 50\n",
    "url_list_chunks = tuple(chunks(url_list, N_chunks))\n",
    "with ThreadPool(N_chunks) as pool:\n",
    "    results = pool.map(download_files, url_list_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1357c1ff-ce70-4ed1-bfdf-898db37af409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds_genexpr = (xr.load_dataset(f\"{FOLDER_PATH}/{file}\", engine='netcdf4')\n",
    "              for file in files\n",
    "              if '.nc' in file)\n",
    "\n",
    "ds = xr.concat(ds_genexpr, dim='time')\n",
    "ds.to_netcdf(\"historical_wind_data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08597db3-6300-40d1-9223-4fd47d6a7a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
